{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "VBVKq6No-AV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **PRINCIPAL COMPONENT ANALYSIS**"
      ]
    },
    {
      "metadata": {
        "id": "BRCg1zsp-Zse",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.  *** Compute Covaraince Matrix of Data***\n",
        "\n",
        "\n",
        "\n",
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/720/1*kWwfHg0cbL1-4_8yX0VhlA.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "pNjj5l7D-0bw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the mean of the data\n",
        "mean_vec = np.mean(X, axis=0)\n",
        "\n",
        "# Compute the covariance matrix\n",
        "cov_mat = (X - mean_vec).T.dot((X - mean_vec)) / (X.shape[0]-1)\n",
        "\n",
        "\n",
        "# OR this can be done with one line of numpy:\n",
        "cov_mat = np.cov(X.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_pOnqWhE_JBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. ***  Computing Eigen Values and Vectors associated with the covariance matrix***\n",
        "\n",
        "![Texte alternatif…](http://www.sharetechnote.com/image/EngMath_Matrix_Eigen_Eq_02.PNG)"
      ]
    },
    {
      "metadata": {
        "id": "fIfKFMhD_8gm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute the eigen values and vectors using numpy\n",
        "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
        "\n",
        "# Make a list of (eigenvalue, eigenvector) tuples\n",
        "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "\n",
        "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
        "eig_pairs.sort(key=lambda x: x[0], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TH4fs64gAuPF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "3.   ***Projecting data in the new vectors space***\n",
        "\n",
        "Now we are going to project data in the space guide by eigen vectors associated with the the high eeigen values. We can do this in a clever way by looking at the  variance percentage of the  selectec vectors. This percentage quantifies how much information (variance) can be attributed to each of the principal components out of the total 100%.\n",
        "\n",
        "Let’s take an example to illustrate. Say we have a dataset which originally has 10 feature vectors. After computing the covariance matrix, we discover that the eigen values are:\n",
        "\n",
        "[12, 10, 8, 7, 5, 1, 0.1, 0.03, 0.005, 0.0009]\n",
        "\n",
        "The total sum of this array is = 43.1359. But the first 6 values represent:\n",
        "\n",
        "42 / 43.1359 = 99.68% of the total! That means that our first 5 eigen vectors effectively hold 99.68% of the variance or information about our dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sGy3OohgCXnA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep  eigen vectors based on the variance percentage which tells us how \n",
        "# much information (variance) can be attributed to each \n",
        "# of the principal components.\n",
        "#in this case we decided to set the treshold to 0.98\n",
        "\n",
        "exp_var_percentage = 0.98 # Threshold of 98% explained variance\n",
        "\n",
        "tot = sum(eig_vals)\n",
        "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "\n",
        "num_vec_to_keep = 0\n",
        "\n",
        "for index, percentage in enumerate(cum_var_exp):\n",
        "  if percentage > exp_var_percentage:\n",
        "    num_vec_to_keep = index + 1\n",
        "    break\n",
        "    \n",
        "    \n",
        "# Compute the projection matrix based on the top eigen vectors\n",
        "num_features = X.shape[1]\n",
        "proj_mat = eig_pairs[0][1].reshape(num_features,1)\n",
        "for eig_vec_idx in range(1, num_vec_to_keep):\n",
        "  proj_mat = np.hstack((proj_mat, eig_pairs[eig_vec_idx][1].reshape(num_features,1)))\n",
        "\n",
        "# Project the data \n",
        "pca_data = X.dot(proj_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}